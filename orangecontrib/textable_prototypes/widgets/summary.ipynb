{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récapitulation extractive de textes avec Python\n",
    "Cette méthode utilise **Scikit-learn** et **spaCy** pour sélectionner les phrases les plus importantes dans un texte donné. Les phrases vont être gardées en entier.  \n",
    "Une phrase est délimitée par un **.** ou **;**.  \n",
    "#### Avantage  \n",
    "Permettrait un résumé plus robuste - puisque l'algorithme aura des informations extérieures au texte, les STOP_WORDS.\n",
    "#### Désavantage\n",
    "Le désavantage est qu'il y a plus d'installations à faire.  \n",
    "\n",
    "Installation des librairies:\n",
    "- `$ pip install -U spacy`\n",
    "- `$ pip install -U scikit-learn`  \n",
    "\n",
    "Télécharger les langages voulus:\n",
    "- Anglais `$ python -m spacy download en_core_news_sm`\n",
    "- Portugais `$ python -m spacy download pt_core_news_sm`\n",
    "- Français `$ python -m spacy download fr_core_news_sm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import spacy\n",
    "from spacy.lang.pt.stop_words import STOP_WORDS\n",
    "# from spacy.lang.en.stop_words import STOP_WORDS\n",
    "# from spacy.lang.fr.stop_words import STOP_WORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load the packages by name with Spacy built in load()\n",
    "nlpPT = spacy.load(\"pt_core_news_sm\")\n",
    "nlpFR = spacy.load(\"fr_core_news_sm\")\n",
    "nlpEN = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get content from txt examples\n",
    "with open('frankEN.txt') as f: textEN = f.read()\n",
    "docEN = nlpEN(textEN)\n",
    "with open('frankFR.txt') as f: textFR = f.read()\n",
    "docFR = nlpFR(textFR)\n",
    "with open('frankPT.txt') as f: textPT = f.read()\n",
    "docPT = nlpPT(textPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette étape n'est pas sur ce notebook, mais il faudrait aussi une étape **preprocess** ? \n",
    "Ou est-ce que c'est déjà fait par le widget en question ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will continue with the portuguese example\n",
    "corpus = [sent.text.lower() for sent in docPT.sents ]\n",
    "# Remove stopwords: provide little to no useful information\n",
    "cv = CountVectorizer(stop_words=list(STOP_WORDS))   \n",
    "\n",
    "cv_fit=cv.fit_transform(corpus)  \n",
    "\n",
    "# Count unique words and how many times they appear\n",
    "word_list = cv.get_feature_names();    \n",
    "count_list = cv_fit.toarray().sum(axis=0)\n",
    "\n",
    "# Create dictionnary of word frequency\n",
    "word_frequency = dict(zip(word_list,count_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort the dictionnary\n",
    "This next cell will first **sort the dictionnary** we juste created,  \n",
    "then get the **relative frequency** of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Words with higher frequencies:  ['amigo', 'anos', 'outro', 'tenha']\n"
     ]
    }
   ],
   "source": [
    "# Get sorted dict of word frequency and print the top to test\n",
    "val=sorted(word_frequency.values())\n",
    "higher_word_frequencies = [word for word,freq in word_frequency.items() if freq in val[-3:]]\n",
    "print(\"\\nWords with higher frequencies: \", higher_word_frequencies)\n",
    "\n",
    "# gets relative frequency of words\n",
    "higher_frequency = val[-1]\n",
    "for word in word_frequency.keys():  \n",
    "    word_frequency[word] = (word_frequency[word]/higher_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 24, 23, 22, 22]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise a sentence dictionnary\n",
    "sentence_rank={}\n",
    "\n",
    "# For each word in each sentence ... \n",
    "for sent in docPT.sents:\n",
    "    for word in sent :    \n",
    "        # if the word appears in word_frequency dict\n",
    "        if word.text.lower() in word_frequency.keys(): \n",
    "            # Add \"points\"\n",
    "            if sent in sentence_rank.keys():\n",
    "                sentence_rank[sent]+=word_frequency[word.text.lower()]\n",
    "            else:\n",
    "                sentence_rank[sent]=word_frequency[word.text.lower()]\n",
    "                \n",
    "# Sort sentences\n",
    "top_sentences=(sorted(sentence_rank.values())[::-1])\n",
    "# This is where we can choose how many sentences we want to keep for the summary\n",
    "top_sent=top_sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Não tenho ninguém próximo a mim, sereno e corajoso, que tenha uma mentalidade elevada e aberta, cujas aptidões sejam iguais às minhas, para aprovar ou corrigir meus planos. e eu realmente anseio por um amigo que tenha discernimento suficiente para não me ver como um sonhador e paciência para ajudar-me a organizar minhas idéias. Passei a juventude em solidão, vivi meus melhores anos em sua suave e feminina companhia, e isso moldou meu caráter de tal forma que sou incapaz de superar o desgosto intenso que me causa a brutalidade, tão comum nos navios. Há alguns anos ele amou uma jovem senhora russa de pequena fortuna e, como ele havia ganho uma considerável quantia em dinheiro, o pai da moça consentiu no casamento. Na prática, sou muito ativo, trabalhador, um operário pronto a executar tudo com perseverança, mas ao lado disso há um amor, uma crença no assombroso inserida em todos os meus projetos, que me coloca distante dos caminhos normais dos homens, impelindo-me para o mar bravo. "
     ]
    }
   ],
   "source": [
    "# We can now create a summary from those sentences:\n",
    "summary=[]\n",
    "for sent,strength in sentence_rank.items():  \n",
    "    if strength in top_sent:\n",
    "        summary.append(sent)\n",
    "    else:\n",
    "        continue\n",
    "for i in summary:\n",
    "    print(i,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method will also work with other langages, as long as the correct nlp and correct STOP_WORDS list is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
